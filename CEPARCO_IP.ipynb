{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichaelGelo/GRP2_CEPARCO_IP/blob/main/CEPARCO_IP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Group 2 - Implementing Hyyrö’s Bit Vector Algorithm Using CUDA SIMT**\n",
        "## **GROUP 2 - S11**\n",
        "\n",
        "**MEMBERS:**\n",
        "\n",
        "- Alfred Bastin S. Agustines\n",
        "- Allan David C. De Leon\n",
        "- Michael Angelo Depasucat\n",
        "- Kai Hiori J. Padilla\n"
      ],
      "metadata": {
        "id": "lYFAEMSCjMia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check if CUDA is present"
      ],
      "metadata": {
        "id": "F2WHo8MojeI2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMQ6IHLDh37V",
        "outputId": "bebe11d5-3039-497c-d6ba-522b79124272",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Mar 12 14:11:25 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename, content in uploaded.items():\n",
        "    with open(filename, \"wb\") as f:\n",
        "        f.write(content)"
      ],
      "metadata": {
        "id": "FKdIwT_WtmVA",
        "outputId": "847408a2-8b86-49b8-a89c-df2680ab55a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-94e19b7e-c845-430c-bc8d-c44803370e4c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-94e19b7e-c845-430c-bc8d-c44803370e4c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving GQ167802.1.txt to GQ167802.1.txt\n",
            "Saving MN481274.1.txt to MN481274.1.txt\n",
            "Saving OP828680.1.txt to OP828680.1.txt\n",
            "Saving NM_153796.4.txt to NM_153796.4.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload Files"
      ],
      "metadata": {
        "id": "iPd2GXswtm5-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##C"
      ],
      "metadata": {
        "id": "NYfqCa2OltNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile C_hyyro.c\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "#include <stdint.h>\n",
        "#include <time.h>\n",
        "\n",
        "#define MAX_LENGTH (1 << 24)\n",
        "\n",
        "typedef uint64_t bitvector;\n",
        "\n",
        "int bit_vector_levenshtein(const char *query, const char *reference) {\n",
        "    int m = strlen(query);\n",
        "    int n = strlen(reference);\n",
        "    if (m > MAX_LENGTH || n > MAX_LENGTH) {\n",
        "        printf(\"Error: Strings too long for this implementation!\\n\");\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    bitvector Pv = ~0ULL;\n",
        "    bitvector Mv = 0;\n",
        "    bitvector Eq[256] = {0};\n",
        "    bitvector Ph, Mh, Xv, Xh, Xp;\n",
        "\n",
        "    for (int i = 0; i < m; i++) {\n",
        "        Eq[(unsigned char)query[i]] |= (1ULL << i);\n",
        "    }\n",
        "\n",
        "    int score = m;\n",
        "\n",
        "    for (int j = 0; j < n; j++) {\n",
        "        Xv = Eq[(unsigned char)reference[j]] | Mv;\n",
        "        Xh = ((~Xh & Xv) << 1) & Xp;\n",
        "\n",
        "        Xh = Xh | ((Xv & Pv) + Pv) ^ Pv | Xv | Mv;\n",
        "        Ph = Mv | ~(Xh | Pv);\n",
        "        Mh = Xh & Pv;\n",
        "        Xp = Xv;\n",
        "\n",
        "        if (Ph & (1ULL << (m - 1))) score++;\n",
        "        if (Mh & (1ULL << (m - 1))) score--;\n",
        "\n",
        "        Xv = (Ph << 1);\n",
        "        Pv = (Mh << 1) | ~(Xh | Xv);\n",
        "        Mv = Xh & Xv;\n",
        "    }\n",
        "\n",
        "    return score;\n",
        "}\n",
        "\n",
        "char* read_file_into_string(const char* filename) {\n",
        "    FILE* file = fopen(filename, \"r\");\n",
        "    if (!file) {\n",
        "        perror(\"Failed to open file\");\n",
        "        return NULL;\n",
        "    }\n",
        "\n",
        "\n",
        "    fseek(file, 0, SEEK_END);\n",
        "    long file_size = ftell(file);\n",
        "    fseek(file, 0, SEEK_SET);\n",
        "\n",
        "    char* buffer = (char*)malloc(file_size + 1);\n",
        "    if (!buffer) {\n",
        "        perror(\"Failed to allocate memory\");\n",
        "        fclose(file);\n",
        "        return NULL;\n",
        "    }\n",
        "\n",
        "\n",
        "    size_t bytes_read = fread(buffer, 1, file_size, file);\n",
        "    if (bytes_read < file_size) {\n",
        "        perror(\"Failed to read the file\");\n",
        "        free(buffer);\n",
        "        fclose(file);\n",
        "        return NULL;\n",
        "    }\n",
        "\n",
        "    buffer[bytes_read] = '\\0';\n",
        "\n",
        "    fclose(file);\n",
        "    return buffer;\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "    const size_t loope = 10;\n",
        "    clock_t start, end;\n",
        "    double elapse = 0.0f;\n",
        "\n",
        "    const char *query = \"tcg\";\n",
        "        // Reference sequences to process\n",
        "    const char* filenames[] = {\"GQ167802.1.txt\"};\n",
        "    int num_references = sizeof(filenames) / sizeof(filenames[0]);\n",
        "\n",
        "    // Array to store the reference sequences\n",
        "    const char* references_input[num_references];\n",
        "    int reference_lengths[num_references];\n",
        "\n",
        "    for (int i = 0; i < num_references; i++) {\n",
        "        references_input[i] = read_file_into_string(filenames[i]);\n",
        "        if (!references_input[i]) {\n",
        "            fprintf(stderr, \"Error reading file: %s\\n\", filenames[i]);\n",
        "\n",
        "            // Free any previously allocated memory before exiting\n",
        "            for (int j = 0; j < i; j++) {\n",
        "                free((void*)references_input[j]);\n",
        "            }\n",
        "            return -1;\n",
        "        }\n",
        "\n",
        "    }\n",
        "\n",
        "    printf(\"Reference: \");\n",
        "    printf(\"Query: %s\\n\", query);\n",
        "\n",
        "    for (int i = 0; i < num_references; i++) {\n",
        "        bit_vector_levenshtein(query, references_input[i]);\n",
        "        printf(\"%s\", references_input[i]);\n",
        "\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    for (int i = 0; i < loope; i++) {\n",
        "      start = clock();\n",
        "      for (int j = 0; j < num_references; j++) {\n",
        "\n",
        "        bit_vector_levenshtein(query, references_input[j]);\n",
        "\n",
        "        }\n",
        "        end = clock();\n",
        "        elapse += ((double)(end - start)) * 1E3 / CLOCKS_PER_SEC;\n",
        "    }\n",
        "    printf(\"Function (in C) average time for %lu loops is %f milliseconds\\n\", loope, elapse / loope);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "kRPhGmz5lxu_",
        "outputId": "827a5c4c-0ff8-414b-f96f-7e595d963dff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting C_hyyro.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "gcc C_hyyro.c -o C_hyyro"
      ],
      "metadata": {
        "id": "hmlgNZSQnuiw",
        "outputId": "08e4d52c-5954-40ce-bc0b-5910b5e5c4a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "./C_hyyro"
      ],
      "metadata": {
        "id": "wdjR7db7nzFB",
        "outputId": "56504d9f-6228-42ad-fea2-4e46ba214ce5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reference: Query: tcg\n",
            "ctttttggcttaggccttggcaccacaattacatttgctagctcccactgacttcttgcctgaataggccttgaaataaatacactagccattattcccctaatagctcaacatcatcacccccgcgctgtcgaagctacaactaaatattttttaacccaagctgctgctgcagccactcttctatttgcaagcattactaacgcctgactaacaggccaatgagaaattcaacaaattacacatcccctcccaaccacaataattacccttgcccttgccctcaaaatcggtcttgccccccttcatgcttgactccccgaagttttacaaggactagatcttaccacaggattaatcctctcaacctgacaaaaacttgctcccttcgccctaatccttcaaatccaaccttcaaactcaaccctcctcatcattttaggccttgcatccacccttatcggcggctgaggcgggttaaaccaaacacagctccgtaaaatccttgcatattcatcaatcgcccatctaggctgaataattcttgttttacaattttcaccctcaattacacttctcaccctcctcacctactttattataacattctcaacattccttatcttcaaactcaacaaatccacaaacattaacactcttgctatatcctggacgaaagctcctgccctcacagctctcacccccctcgtcctcctctcactagggggccttccccctcttacaggctttataccaaaatgactaattcttcaagaactagccaaacaagaccttgcccccgccgccaccctagcagccctctcagcccttctcagcctatatttttacctacgcctttcttatgcaataaccctcacgatttccccaaacaatcttacaagcacaactccctgacgcctaccttccacccagctaacttaccctctcgccacttcaaccgccataacaatctgccttctaccccttacccccgccatttctgcctta\n",
            "Function (in C) average time for 10 loops is 0.016900 milliseconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CUDA"
      ],
      "metadata": {
        "id": "iZ2Zjg52jlxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CUDA.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <stdint.h>\n",
        "#include <string.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Prefetch + page creation + memadvise\n",
        "#define MAX_LENGTH (1 << 24)\n",
        "typedef uint64_t bitvector;\n",
        "__constant__ bitvector d_Eq[256];\n",
        "\n",
        "__host__ __device__ int bit_vector_levenshtein(int query_length, const char *reference, int reference_length, const bitvector *Eq) {\n",
        "    if (query_length > MAX_LENGTH || reference_length > MAX_LENGTH) {\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    bitvector Pv = ~0ULL;\n",
        "    bitvector Mv = 0;\n",
        "    bitvector Ph = 0;\n",
        "    bitvector Mh = 0;\n",
        "    bitvector Xv = 0;\n",
        "    bitvector Xh = 0;\n",
        "    bitvector Xp = 0;\n",
        "    int score = query_length;\n",
        "\n",
        "    for (int j = 0; j < reference_length; j++) {\n",
        "        unsigned char c = reference[j];\n",
        "        Xv = Eq[c] | Mv;\n",
        "\n",
        "        Xh = ((~Xh & Xv) << 1) & Xp;\n",
        "\n",
        "        // Explicit parentheses for clarity\n",
        "        Xh = Xh | ((((Xv & Pv) + Pv) ^ Pv) | Xv | Mv);\n",
        "\n",
        "        Ph = Mv | ~(Xh | Pv);\n",
        "        Mh = Xh & Pv;\n",
        "        Xp = Xv;\n",
        "\n",
        "        if (Ph & (1ULL << (query_length - 1))) score++;\n",
        "        if (Mh & (1ULL << (query_length - 1))) score--;\n",
        "\n",
        "        Xv = (Ph << 1);\n",
        "        Pv = (Mh << 1) | ~(Xh | Xv);\n",
        "        Mv = Xh & Xv;\n",
        "    }\n",
        "\n",
        "    return score;\n",
        "}\n",
        "\n",
        "__global__ void levenshtein_kernel(int query_length, const char *references, const int *reference_lengths, int *distances, int num_references) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "    for (int i = idx; i < num_references; i += stride) {\n",
        "        const char *reference = &references[i * MAX_LENGTH];\n",
        "        int reference_length = reference_lengths[i];\n",
        "        // Use the constant memory table on the device.\n",
        "        distances[i] = bit_vector_levenshtein(query_length, reference, reference_length, d_Eq);\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "char* read_file_into_string(const char* filename) {\n",
        "    FILE* file = fopen(filename, \"r\");\n",
        "    if (!file) {\n",
        "        perror(\"Failed to open file\");\n",
        "        return NULL;\n",
        "    }\n",
        "\n",
        "\n",
        "    fseek(file, 0, SEEK_END);\n",
        "    long file_size = ftell(file);\n",
        "    fseek(file, 0, SEEK_SET);\n",
        "\n",
        "    char* buffer = (char*)malloc(file_size + 1);\n",
        "    if (!buffer) {\n",
        "        perror(\"Failed to allocate memory\");\n",
        "        fclose(file);\n",
        "        return NULL;\n",
        "    }\n",
        "\n",
        "\n",
        "    size_t bytes_read = fread(buffer, 1, file_size, file);\n",
        "    if (bytes_read < file_size) {\n",
        "        perror(\"Failed to read the file\");\n",
        "        free(buffer);\n",
        "        fclose(file);\n",
        "        return NULL;\n",
        "    }\n",
        "\n",
        "    buffer[bytes_read] = '\\0';\n",
        "\n",
        "    fclose(file);\n",
        "    return buffer;\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "    const char *query = \"ccccc\"; // Query DNA sequence\n",
        "    int query_length = strlen(query);\n",
        "    if (query_length > MAX_LENGTH) {\n",
        "        printf(\"Query sequence too long!\\n\");\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    // Precompute Eq for the query and store it in host memory.\n",
        "    bitvector h_Eq[256] = {0};\n",
        "    for (int i = 0; i < query_length; i++) {\n",
        "        h_Eq[(unsigned char)query[i]] |= (1ULL << i);\n",
        "    }\n",
        "\n",
        "    // Copy Eq to constant memory on the device.\n",
        "    cudaMemcpyToSymbol(d_Eq, h_Eq, sizeof(bitvector) * 256);\n",
        "\n",
        "    // Reference sequences to process\n",
        "    const char* filenames[] = {\"GQ167802.1.txt\", \"MN481274.1.txt\"};\n",
        "    int num_references = sizeof(filenames) / sizeof(filenames[0]);\n",
        "\n",
        "    // Array to store the reference sequences\n",
        "    const char* references_input[num_references];\n",
        "    int reference_lengths[num_references];\n",
        "\n",
        "    for (int i = 0; i < num_references; i++) {\n",
        "        references_input[i] = read_file_into_string(filenames[i]);\n",
        "        if (!references_input[i]) {\n",
        "            fprintf(stderr, \"Error reading file: %s\\n\", filenames[i]);\n",
        "\n",
        "            // Free any previously allocated memory before exiting\n",
        "            for (int j = 0; j < i; j++) {\n",
        "                free((void*)references_input[j]);\n",
        "            }\n",
        "            return -1;\n",
        "        }\n",
        "\n",
        "    }\n",
        "\n",
        "    // Allocate Unified Memory\n",
        "    char *references;\n",
        "    int *d_reference_lengths, *d_distances;\n",
        "    cudaMallocManaged(&references, num_references * MAX_LENGTH * sizeof(char));\n",
        "    cudaMallocManaged(&d_reference_lengths, num_references * sizeof(int));\n",
        "    cudaMallocManaged(&d_distances, num_references * sizeof(int));\n",
        "\n",
        "    // Copy references and lengths to managed memory\n",
        "    for (int i = 0; i < num_references; i++) {\n",
        "        strncpy(&references[i * MAX_LENGTH], references_input[i], MAX_LENGTH);\n",
        "        d_reference_lengths[i] = reference_lengths[i];\n",
        "    }\n",
        "\n",
        "    // Get GPU device ID\n",
        "    int device = -1;\n",
        "    cudaGetDevice(&device);\n",
        "\n",
        "    // Memory advise\n",
        "    cudaMemAdvise(references, num_references * MAX_LENGTH * sizeof(char), cudaMemAdviseSetReadMostly, device);\n",
        "    cudaMemAdvise(d_reference_lengths, num_references * sizeof(int), cudaMemAdviseSetReadMostly, device);\n",
        "    cudaMemAdvise(d_distances, num_references * sizeof(int), cudaMemAdviseSetPreferredLocation, device);\n",
        "\n",
        "    // Prefetch data\n",
        "    cudaMemPrefetchAsync(references, num_references * MAX_LENGTH * sizeof(char), device, NULL);\n",
        "    cudaMemPrefetchAsync(d_reference_lengths, num_references * sizeof(int), device, NULL);\n",
        "    cudaMemPrefetchAsync(d_distances, num_references * sizeof(int), device, NULL);\n",
        "\n",
        "    // Kernel parameters\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (num_references + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    // Number of times the program is executed\n",
        "    const size_t loope = 10;\n",
        "\n",
        "    printf(\"*** function = Levenshtein Distance\\n\");\n",
        "    printf(\"numReferences = %d\\n\", num_references);\n",
        "    printf(\"numBlocks = %d, numThreads = %d\\n\", blocksPerGrid, threadsPerBlock);\n",
        "\n",
        "    // Execute kernel multiple times\n",
        "    for (size_t i = 0; i < loope; i++) {\n",
        "        levenshtein_kernel<<<blocksPerGrid, threadsPerBlock>>>(query_length, references, d_reference_lengths, d_distances, num_references);\n",
        "    }\n",
        "\n",
        "    // Synchronize device\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Prefetch distances back to CPU\n",
        "    cudaMemPrefetchAsync(d_distances, num_references * sizeof(int), cudaCpuDeviceId, NULL);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Error checking: compute expected distance on host using the host copy of Eq (h_Eq).\n",
        "    size_t err_count = 0;\n",
        "    for (int i = 0; i < num_references; i++) {\n",
        "        int expected_distance = bit_vector_levenshtein(query_length, references_input[i], reference_lengths[i], h_Eq);\n",
        "        if (d_distances[i] != expected_distance) {\n",
        "            err_count++;\n",
        "        }\n",
        "    }\n",
        "    printf(\"Error count (CUDA program): %zu\\n\", err_count);\n",
        "\n",
        "    // Print results\n",
        "    for (int i = 0; i < num_references; i++) {\n",
        "        printf(\"Edit Distance between query \\\"%s\\\" and reference \\\"%s\\\" is: %d\\n\", query, references_input[i], d_distances[i]);\n",
        "    }\n",
        "\n",
        "    // Free memory\n",
        "    cudaFree(references);\n",
        "    cudaFree(d_reference_lengths);\n",
        "    cudaFree(d_distances);\n",
        "\n",
        "    for (int i = 0; i < num_references; i++) {\n",
        "        free((void*)references_input[i]);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "N9wXykapjxso",
        "outputId": "7c81cc9d-511a-4886-e1a7-beded141f798",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting CUDA.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc -o CUDA CUDA.cu -arch=sm_75"
      ],
      "metadata": {
        "id": "1_dANIuzj6pA",
        "outputId": "e4020f16-9919-4ab6-937a-5eeb9c4fab80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./CUDA"
      ],
      "metadata": {
        "id": "ClK1DA0Dj-QB",
        "outputId": "21ccf74d-8a1d-4b22-b331-556b49a70cbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==4064== NVPROF is profiling process 4064, command: ./CUDA\n",
            "*** function = Levenshtein Distance\n",
            "numReferences = 2\n",
            "numBlocks = 1, numThreads = 256\n",
            "Error count (CUDA program): 0\n",
            "Edit Distance between query \"ccccc\" and reference \"ctttttggcttaggccttggcaccacaattacatttgctagctcccactgacttcttgcctgaataggccttgaaataaatacactagccattattcccctaatagctcaacatcatcacccccgcgctgtcgaagctacaactaaatattttttaacccaagctgctgctgcagccactcttctatttgcaagcattactaacgcctgactaacaggccaatgagaaattcaacaaattacacatcccctcccaaccacaataattacccttgcccttgccctcaaaatcggtcttgccccccttcatgcttgactccccgaagttttacaaggactagatcttaccacaggattaatcctctcaacctgacaaaaacttgctcccttcgccctaatccttcaaatccaaccttcaaactcaaccctcctcatcattttaggccttgcatccacccttatcggcggctgaggcgggttaaaccaaacacagctccgtaaaatccttgcatattcatcaatcgcccatctaggctgaataattcttgttttacaattttcaccctcaattacacttctcaccctcctcacctactttattataacattctcaacattccttatcttcaaactcaacaaatccacaaacattaacactcttgctatatcctggacgaaagctcctgccctcacagctctcacccccctcgtcctcctctcactagggggccttccccctcttacaggctttataccaaaatgactaattcttcaagaactagccaaacaagaccttgcccccgccgccaccctagcagccctctcagcccttctcagcctatatttttacctacgcctttcttatgcaataaccctcacgatttccccaaacaatcttacaagcacaactccctgacgcctaccttccacccagctaacttaccctctcgccacttcaaccgccataacaatctgccttctaccccttacccccgccatttctgcctta\" is: -1\n",
            "Edit Distance between query \"ccccc\" and reference \"atgacaaatctccgaaaaacccaccccctactaaaaattgcaaacgacgcattagttgacctccccacacccgtcaatatttcagcttgatgaaactttggctccctacttggcctttgtctcatcgctcaaattcttacaggcctattccttacaatacactactgctcggacatcacagccgccttttcctccgtcgcacacatctgccgtgacgtgaattacggctgactaattcgaaacatgcacgctaacggagcttccttcttctttatctgcatctacatacacatcggccgagggctatactacggctcatacctatacaaaaacacctgaaatgtcggagtagtccttctcctactagtaataataaccgcctttgttggctacgtacttccttgaggccaaatatccttttgaggtgctaccgtcattacaaacctgctttcagcagtaccctatatcggcaactcccttgttcaatgaatctgaggaggcttctccgtagataacgccaccctcacacgattcctagccttccatttccttctcccctttgttattgcagcaataacaatagtccacctcattttcctacacgaaacagggtcgaacaacccaacaggtttaaactcagatgcagacaaaatctcgttccacccgtatttctcctataaagacctgctaggtttcacaatcctcctcctcggcttaacctccctagccctttttctacccaacctcctcggagacccagacaacttcacccccgccaatcctttgataactcctccccacattaaaccagagtggtacttcctatttgcctacgccattctccgctctatccccaacaaactaggaggagtacttgcacttctattctcaatcctagttttgatagtcgtcccgattcttcacacctctaagcagcaaagcctcaccttccgacccctcgcccaactattattctgactcctaattgcagatgtaattatcctcacttgaatcggaggaatgccagttgaacacccctttgttattatcgggcaagcagcatctctcctgtacttcataatttttctcattctcatgcctgccgccagctgagtagaaaacaaactaattaactggtaac\" is: 5\n",
            "==4064== Profiling application: ./CUDA\n",
            "==4064== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  48.962ms        10  4.8962ms  4.8783ms  5.0570ms  levenshtein_kernel(int, char const *, int const *, int*, int)\n",
            "                    0.00%     832ns         1     832ns     832ns     832ns  [CUDA memcpy HtoD]\n",
            "      API calls:   74.03%  237.45ms         1  237.45ms  237.45ms  237.45ms  cudaMemcpyToSymbol\n",
            "                   15.86%  50.876ms         2  25.438ms  5.0370us  50.871ms  cudaDeviceSynchronize\n",
            "                    6.35%  20.380ms         3  6.7932ms  24.977us  20.254ms  cudaMallocManaged\n",
            "                    1.18%  3.7898ms         4  947.45us  57.465us  3.5467ms  cudaMemPrefetchAsync\n",
            "                    1.05%  3.3544ms         3  1.1181ms  48.559us  2.3051ms  cudaMemAdvise\n",
            "                    0.80%  2.5726ms         1  2.5726ms  2.5726ms  2.5726ms  cuDeviceGetPCIBusId\n",
            "                    0.62%  1.9976ms         3  665.87us  33.937us  1.0190ms  cudaFree\n",
            "                    0.05%  149.93us       114  1.3150us     108ns  63.033us  cuDeviceGetAttribute\n",
            "                    0.05%  147.48us        10  14.747us  4.9380us  88.992us  cudaLaunchKernel\n",
            "                    0.00%  12.385us         1  12.385us  12.385us  12.385us  cuDeviceGetName\n",
            "                    0.00%  3.7890us         1  3.7890us  3.7890us  3.7890us  cudaGetDevice\n",
            "                    0.00%  1.6480us         3     549ns     115ns  1.3290us  cuDeviceGetCount\n",
            "                    0.00%     809ns         2     404ns     138ns     671ns  cuDeviceGet\n",
            "                    0.00%     501ns         1     501ns     501ns     501ns  cuDeviceTotalMem\n",
            "                    0.00%     448ns         1     448ns     448ns     448ns  cuModuleGetLoadingMode\n",
            "                    0.00%     256ns         1     256ns     256ns     256ns  cuDeviceGetUuid\n",
            "\n",
            "==4064== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "      17  1.8826MB  4.0000KB  2.0000MB  32.00391MB  2.783495ms  Host To Device\n",
            "       1  4.0000KB  4.0000KB  4.0000KB  4.000000KB  1.824000us  Device To Host\n",
            "       1         -         -         -           -  78.17500us  Gpu page fault groups\n",
            "Total CPU Page faults: 97\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}