{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichaelGelo/GRP2_CEPARCO_IP/blob/main/CEPARCO_IP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Group 2 - Implementing Hyyrö’s Bit Vector Algorithm Using CUDA SIMT**\n",
        "## **GROUP 2 - S11**\n",
        "\n",
        "**MEMBERS:**\n",
        "\n",
        "- Alfred Bastin S. Agustines\n",
        "- Allan David C. De Leon\n",
        "- Michael Angelo Depasucat\n",
        "- Kai Hiori J. Padilla\n"
      ],
      "metadata": {
        "id": "lYFAEMSCjMia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check if CUDA is present"
      ],
      "metadata": {
        "id": "F2WHo8MojeI2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FMQ6IHLDh37V",
        "outputId": "22c20ea5-bbc8-440b-cd37-6bbd2941f99a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Mar 10 14:37:03 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Integrating Project"
      ],
      "metadata": {
        "id": "iZ2Zjg52jlxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CUDA.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <stdint.h>\n",
        "#include <string.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Prefetch + page creation + memadvise\n",
        "#define MAX_LENGTH 64\n",
        "typedef uint64_t bitvector;\n",
        "__constant__ bitvector d_Eq[256];\n",
        "\n",
        "// CUDA Levenshtein function now accepts a pointer to the Eq lookup table.\n",
        "// This allows using the device constant memory on the GPU and a host copy on the CPU.\n",
        "__host__ __device__ int bit_vector_levenshtein(int query_length, const char *reference, int reference_length, const bitvector *Eq) {\n",
        "    if (query_length > MAX_LENGTH || reference_length > MAX_LENGTH) {\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    bitvector Pv = ~0ULL;\n",
        "    bitvector Mv = 0;\n",
        "    bitvector Ph = 0;\n",
        "    bitvector Mh = 0;\n",
        "    bitvector Xv = 0;\n",
        "    bitvector Xh = 0;\n",
        "    bitvector Xp = 0;\n",
        "    int score = query_length;\n",
        "\n",
        "    for (int j = 0; j < reference_length; j++) {\n",
        "        unsigned char c = reference[j];\n",
        "        Xv = Eq[c] | Mv;\n",
        "\n",
        "        Xh = ((~Xh & Xv) << 1) & Xp;\n",
        "\n",
        "        // Explicit parentheses for clarity\n",
        "        Xh = Xh | ((((Xv & Pv) + Pv) ^ Pv) | Xv | Mv);\n",
        "\n",
        "        Ph = Mv | ~(Xh | Pv);\n",
        "        Mh = Xh & Pv;\n",
        "        Xp = Xv;\n",
        "\n",
        "        if (Ph & (1ULL << (query_length - 1))) score++;\n",
        "        if (Mh & (1ULL << (query_length - 1))) score--;\n",
        "\n",
        "        Xv = (Ph << 1);\n",
        "        Pv = (Mh << 1) | ~(Xh | Xv);\n",
        "        Mv = Xh & Xv;\n",
        "    }\n",
        "\n",
        "    return score;\n",
        "}\n",
        "\n",
        "__global__ void levenshtein_kernel(int query_length, const char *references, const int *reference_lengths, int *distances, int num_references) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "    for (int i = idx; i < num_references; i += stride) {\n",
        "        const char *reference = &references[i * MAX_LENGTH];\n",
        "        int reference_length = reference_lengths[i];\n",
        "        // Use the constant memory table on the device.\n",
        "        distances[i] = bit_vector_levenshtein(query_length, reference, reference_length, d_Eq);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    const char *query = \"tcg\"; // Query DNA sequence\n",
        "    int query_length = strlen(query);\n",
        "    if (query_length > MAX_LENGTH) {\n",
        "        printf(\"Query sequence too long!\\n\");\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    // Precompute Eq for the query and store it in host memory.\n",
        "    bitvector h_Eq[256] = {0};\n",
        "    for (int i = 0; i < query_length; i++) {\n",
        "        h_Eq[(unsigned char)query[i]] |= (1ULL << i);\n",
        "    }\n",
        "\n",
        "    // Copy Eq to constant memory on the device.\n",
        "    cudaMemcpyToSymbol(d_Eq, h_Eq, sizeof(bitvector) * 256);\n",
        "\n",
        "    // Reference sequences to process\n",
        "    const char *references_input[] = { \"attattcga\", \"atttcatctcgt\" }; // Reference DNA sequences (Dummy lang toh, palagay ako ng actua data)\n",
        "    int num_references = 2;\n",
        "    int reference_lengths[num_references];\n",
        "    for (int i = 0; i < num_references; i++) {\n",
        "        reference_lengths[i] = strlen(references_input[i]);\n",
        "        if (reference_lengths[i] > MAX_LENGTH) {\n",
        "            printf(\"Reference sequence %d too long!\\n\", i);\n",
        "            return -1;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Allocate Unified Memory\n",
        "    char *references;\n",
        "    int *d_reference_lengths, *d_distances;\n",
        "    cudaMallocManaged(&references, num_references * MAX_LENGTH * sizeof(char));\n",
        "    cudaMallocManaged(&d_reference_lengths, num_references * sizeof(int));\n",
        "    cudaMallocManaged(&d_distances, num_references * sizeof(int));\n",
        "\n",
        "    // Copy references and lengths to managed memory\n",
        "    for (int i = 0; i < num_references; i++) {\n",
        "        strncpy(&references[i * MAX_LENGTH], references_input[i], MAX_LENGTH);\n",
        "        d_reference_lengths[i] = reference_lengths[i];\n",
        "    }\n",
        "\n",
        "    // Get GPU device ID\n",
        "    int device = -1;\n",
        "    cudaGetDevice(&device);\n",
        "\n",
        "    // Memory advise\n",
        "    cudaMemAdvise(references, num_references * MAX_LENGTH * sizeof(char), cudaMemAdviseSetReadMostly, device);\n",
        "    cudaMemAdvise(d_reference_lengths, num_references * sizeof(int), cudaMemAdviseSetReadMostly, device);\n",
        "    cudaMemAdvise(d_distances, num_references * sizeof(int), cudaMemAdviseSetPreferredLocation, device);\n",
        "\n",
        "    // Prefetch data\n",
        "    cudaMemPrefetchAsync(references, num_references * MAX_LENGTH * sizeof(char), device, NULL);\n",
        "    cudaMemPrefetchAsync(d_reference_lengths, num_references * sizeof(int), device, NULL);\n",
        "    cudaMemPrefetchAsync(d_distances, num_references * sizeof(int), device, NULL);\n",
        "\n",
        "    // Kernel parameters\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (num_references + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    // Number of times the program is executed\n",
        "    const size_t loope = 10;\n",
        "\n",
        "    printf(\"*** function = Levenshtein Distance\\n\");\n",
        "    printf(\"numReferences = %d\\n\", num_references);\n",
        "    printf(\"numBlocks = %d, numThreads = %d\\n\", blocksPerGrid, threadsPerBlock);\n",
        "\n",
        "    // Execute kernel multiple times\n",
        "    for (size_t i = 0; i < loope; i++) {\n",
        "        levenshtein_kernel<<<blocksPerGrid, threadsPerBlock>>>(query_length, references, d_reference_lengths, d_distances, num_references);\n",
        "    }\n",
        "\n",
        "    // Synchronize device\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Prefetch distances back to CPU\n",
        "    cudaMemPrefetchAsync(d_distances, num_references * sizeof(int), cudaCpuDeviceId, NULL);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Error checking: compute expected distance on host using the host copy of Eq (h_Eq).\n",
        "    size_t err_count = 0;\n",
        "    for (int i = 0; i < num_references; i++) {\n",
        "        int expected_distance = bit_vector_levenshtein(query_length, references_input[i], reference_lengths[i], h_Eq);\n",
        "        if (d_distances[i] != expected_distance) {\n",
        "            err_count++;\n",
        "        }\n",
        "    }\n",
        "    printf(\"Error count (CUDA program): %zu\\n\", err_count);\n",
        "\n",
        "    // Print results\n",
        "    for (int i = 0; i < num_references; i++) {\n",
        "        printf(\"Edit Distance between query \\\"%s\\\" and reference \\\"%s\\\" is: %d\\n\", query, references_input[i], d_distances[i]);\n",
        "    }\n",
        "\n",
        "    // Free memory\n",
        "    cudaFree(references);\n",
        "    cudaFree(d_reference_lengths);\n",
        "    cudaFree(d_distances);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "N9wXykapjxso",
        "outputId": "b4a0b5e7-ae4e-4a95-dcdd-b1565f46d2b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting CUDA.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc CUDA.cu -o CUDA"
      ],
      "metadata": {
        "id": "1_dANIuzj6pA",
        "outputId": "6eee7bc7-5a22-42f4-a322-64421d2797ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./CUDA"
      ],
      "metadata": {
        "id": "ClK1DA0Dj-QB",
        "outputId": "05b0084f-6fe8-4117-e917-14ba0647a67d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==3153== NVPROF is profiling process 3153, command: ./CUDA\n",
            "*** function = Levenshtein Distance\n",
            "numReferences = 2\n",
            "numBlocks = 1, numThreads = 256\n",
            "Error count (CUDA program): 0\n",
            "Edit Distance between query \"tcg\" and reference \"attattcga\" is: 1\n",
            "Edit Distance between query \"tcg\" and reference \"atttcatctcgt\" is: 1\n",
            "==3153== Profiling application: ./CUDA\n",
            "==3153== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   99.33%  124.03us        10  12.402us  5.4720us  74.142us  levenshtein_kernel(int, char const *, int const *, int*, int)\n",
            "                    0.67%     832ns         1     832ns     832ns     832ns  [CUDA memcpy HtoD]\n",
            "      API calls:   80.73%  89.014ms         1  89.014ms  89.014ms  89.014ms  cudaMemcpyToSymbol\n",
            "                   18.51%  20.414ms         3  6.8048ms  5.3390us  20.391ms  cudaMallocManaged\n",
            "                    0.24%  269.22us         4  67.304us  8.4100us  145.70us  cudaMemPrefetchAsync\n",
            "                    0.14%  154.17us         3  51.390us  13.414us  107.15us  cudaFree\n",
            "                    0.13%  148.62us        10  14.861us  6.1350us  48.964us  cudaLaunchKernel\n",
            "                    0.13%  143.28us       114  1.2560us     132ns  56.881us  cuDeviceGetAttribute\n",
            "                    0.05%  60.376us         3  20.125us  2.6800us  49.454us  cudaMemAdvise\n",
            "                    0.03%  33.162us         2  16.581us  1.8360us  31.326us  cudaDeviceSynchronize\n",
            "                    0.01%  13.814us         1  13.814us  13.814us  13.814us  cuDeviceGetName\n",
            "                    0.01%  6.0700us         1  6.0700us  6.0700us  6.0700us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.6730us         1  2.6730us  2.6730us  2.6730us  cudaGetDevice\n",
            "                    0.00%  1.9810us         3     660ns     238ns  1.4530us  cuDeviceGetCount\n",
            "                    0.00%     881ns         2     440ns     168ns     713ns  cuDeviceGet\n",
            "                    0.00%     559ns         1     559ns     559ns     559ns  cuDeviceTotalMem\n",
            "                    0.00%     498ns         1     498ns     498ns     498ns  cuModuleGetLoadingMode\n",
            "                    0.00%     221ns         1     221ns     221ns     221ns  cuDeviceGetUuid\n",
            "\n",
            "==3153== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "       1  4.0000KB  4.0000KB  4.0000KB  4.000000KB  3.200000us  Host To Device\n",
            "       1  4.0000KB  4.0000KB  4.0000KB  4.000000KB  1.792000us  Device To Host\n",
            "       1         -         -         -           -  65.95100us  Gpu page fault groups\n",
            "Total CPU Page faults: 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}